{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkkUx/mbHPbjcm8CgR+KPp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/goel4ever/machine-learning-notebooks/blob/main/nlp_chunking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP: Chunking\n",
        "\n",
        "A `phrase` is a word or group of words that works as a single unit to perform a grammatical function. While `tokenizing` allows you to identify words and sentences, `chunking` allows you to identify phrases.\n",
        "\n",
        "Chunking makes use of `POS tags` to group words and apply chunk tags to those groups. Chunks don't overlap, so one instance of a word can be in only one chunk at a time. This notebook focuses on chunking sentences using Natural Language Processing.\n",
        "\n",
        "We'll use NLTK package for implementation. A group of texts is called a corpus. NLTK provides several corpora covering everything from novels hosted by Project Gutenberg to inaugural speeches by presidents of the United States.\n",
        "\n",
        "In order to analyze texts in NLTK, you first need to import them. We need a one-off run of nltk.download() to get all the resources in one go. Note: It will take some time."
      ],
      "metadata": {
        "id": "mjqiDAXo-9-A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uveZGO3-6Sk",
        "outputId": "188a2513-722d-4645-bb89-2911783579ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "# Download resource punkt for tokenization\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Required imports\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Before you can chunk, you need to make sure that the parts of speech in your text are tagged, so create a string for POS tagging.\n",
        "quote = \"It's a dangerous business, Frodo, going out your door.\""
      ],
      "metadata": {
        "id": "D9epFCZCZYRt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the string by word\n",
        "words_in_quote = word_tokenize(quote)\n",
        "words_in_quote"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXikvhxPZi4b",
        "outputId": "7adec985-df1e-41d5-ba55-342aff691eae"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['It',\n",
              " \"'s\",\n",
              " 'a',\n",
              " 'dangerous',\n",
              " 'business',\n",
              " ',',\n",
              " 'Frodo',\n",
              " ',',\n",
              " 'going',\n",
              " 'out',\n",
              " 'your',\n",
              " 'door',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tag those words by part of speech\n",
        "nltk.download(\"averaged_perceptron_tagger\")\n",
        "pos_tags = nltk.pos_tag(words_in_quote)\n",
        "pos_tags"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "625C1b1KZrXo",
        "outputId": "7a14c0a3-a216-45c0-95ae-11a1014fd46c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('It', 'PRP'),\n",
              " (\"'s\", 'VBZ'),\n",
              " ('a', 'DT'),\n",
              " ('dangerous', 'JJ'),\n",
              " ('business', 'NN'),\n",
              " (',', ','),\n",
              " ('Frodo', 'NNP'),\n",
              " (',', ','),\n",
              " ('going', 'VBG'),\n",
              " ('out', 'RP'),\n",
              " ('your', 'PRP$'),\n",
              " ('door', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In order to chunk, you first need to define a chunk grammar.\n",
        "# A chunk grammar is a combination of rules on how sentences should be chunked.\n",
        "# It often uses regular expressions, or regexes.\n",
        "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
        "\n",
        "# 1. NP stands for noun phrase.\n",
        "# 2. Start with an optional (?) determiner ('DT')\n",
        "# 3. Can have any number (*) of adjectives (JJ)\n",
        "# 4. End with a noun (<NN>)\n",
        "\n",
        "# Read about Noun Phrase chunking here\n",
        "# https://www.nltk.org/book/ch07.html#noun-phrase-chunking"
      ],
      "metadata": {
        "id": "-MlwN2REaC45"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a chunk parser with this grammar\n",
        "chunk_parser = nltk.RegexpParser(grammar)"
      ],
      "metadata": {
        "id": "4fjmuCQWass6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try the parser with the quote, and draw a tree\n",
        "tree = chunk_parser.parse(pos_tags)\n",
        "\n",
        "# This will cause an error in notebooks because there's no display to draw the tree on\n",
        "# tree.draw()\n",
        "print(tree.pretty_print())\n",
        "\n",
        "# You got two noun phrases:\n",
        "# 1. 'a dangerous business' has a determiner, an adjective, and a noun.\n",
        "# 2. 'door' has just a noun."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4g7nAf2oax_r",
        "outputId": "0626d14b-8d00-4460-d0db-d7b2a58a6219"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            S                                                       \n",
            "   _________________________________________|___________________________________________________     \n",
            "  |      |     |      |      |      |       |        |      |            NP                     NP  \n",
            "  |      |     |      |      |      |       |        |      |    ________|____________          |    \n",
            "It/PRP 's/VBZ ,/, Frodo/NNP ,/, going/VBG out/RP your/PRP$ ./. a/DT dangerous/JJ business/NN door/NN\n",
            "\n",
            "None\n"
          ]
        }
      ]
    }
  ]
}